{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This files is for training/generating HMMs with **three states**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Appends the error values of the file(sequence) to X and the length of the sequence to the array lengths. \n",
    "\n",
    "@param filename: name of file/sequence\n",
    "@param X: array of error values for all practice opportunities of one practice mode\n",
    "@param lengths: array of lengths of the individual sequences\n",
    "\"\"\"\n",
    "def get_sequence(filename, X, lengths):\n",
    "    file = pd.read_csv(filename)\n",
    "    for i, row in file.iterrows():\n",
    "        X.append(list(row[4:]))\n",
    "    lengths.append(len(file))\n",
    "    return X, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tries to find the best HMM, by returning the model with the highest score/log probability. Note that this is\n",
    "not necessarily the most reasonable, most-fitting model to the data, so exploring other models is important!\n",
    "\n",
    "@param filename: practice mode\n",
    "\n",
    "@return modelBest: model with the highest logProb\n",
    "@return logProbMax: the highest logProb\n",
    "@return PBest: the transition matrix corresponding to the best model\n",
    "\"\"\"\n",
    "def findBestHMM(filename, X, lengths):\n",
    "    logProbMax = 0\n",
    "    modelBest = None\n",
    "    PBest = None\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            model, mus, sigmas, P, logProb, convergence = fitHMM(X, lengths)\n",
    "            if logProb > logProbMax and convergence.converged == True: #wrong do not use -> all not just highest score\n",
    "                logProbMax = logProb\n",
    "                modelBest = model\n",
    "                PBest = P \n",
    "        except:\n",
    "            continue\n",
    "    with open(filename + \".pkl\", \"wb\") as file: pickle.dump(modelBest, file)\n",
    "    return modelBest, logProbMax, PBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates a Hidden Markov Model. The startprobability and initial transition probability should \n",
    "be varied between retries.\n",
    "\n",
    "@return model:\n",
    "@return mus: means of states\n",
    "@return sigmas: covariance matrix\n",
    "@return P: transition probability\n",
    "@return logProb:score of model\n",
    "@return convergence: monitors convergence of model\n",
    "\"\"\"\n",
    "def fitHMM(X, lengths):\n",
    "    # fit Gaussian HMM to Q\n",
    "    model = hmm.GaussianHMM(n_components=3, n_iter=1000, init_params=\"cm\")\n",
    "    \n",
    "    model.startprob_ = np.array([0.0, 1.0, 0.0]) # same initial state\n",
    "    model.transmat_ = np.array([[0.8, 0.2, 0.0], # initial prob matrix, important is 0 in (1,3) (3,1) (3,2)\n",
    "                                [0.05, 0.8, 0.15],\n",
    "                                [0.0, 0.0, 1.0]])\n",
    "     \n",
    "    model.fit(X, lengths)\n",
    "    # classify each observation as state 0 or 1\n",
    "    #hidden_states = model.predict(X)\n",
    " \n",
    "    # find parameters of Gaussian HMM\n",
    "    convergence = model.monitor_\n",
    "    mus = np.array(model.means_)\n",
    "    sigmas = np.array(np.sqrt(np.array([np.diag(model.covars_[0]),np.diag(model.covars_[1])])))\n",
    "    P = np.array(model.transmat_)\n",
    " \n",
    "    # find log-likelihood of Gaussian HMM\n",
    "    logProb = model.score(X, lengths)\n",
    " \n",
    "    return model, mus, sigmas, P, logProb, convergence #hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n single note\n",
      "P [[1.00000000e+00 4.09542409e-32 0.00000000e+00]\n",
      " [1.66666666e-01 8.20512821e-01 1.28205128e-02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 6731.9710201843145\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[1955.105902295426, 6185.09824157095, 6731.971019215117, 6731.971020184315],\n",
      "    iter=4,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main: Generates models for one practice mode (directory) or iteratively for all (don't forget to save them\n",
    "in that case).\n",
    "\"\"\"\n",
    "#for directory in [\"None\", \"right hand\", \"single note\", \"slower\", \"split hands\", \"both hands\"]:\n",
    "directory = \"single note\"\n",
    "lengths = []\n",
    "X = []\n",
    "for filename in os.listdir(directory):\n",
    "    X, lengths = get_sequence(directory + \"/\" + filename, X, lengths)\n",
    "model, mus, sigmas, P, logProb, convergence = fitHMM(X, lengths) #directory equals practice mode\n",
    "#model, logProb, P = findBestHMM(directory)\n",
    "print(\"/n\", directory)\n",
    "print(\"P\", P)\n",
    "print(\"logProb\", logProb)\n",
    "#print(\"means\", mus)\n",
    "print(\"convergences\", convergence)\n",
    "print(\"\")\n",
    "#with open(\"testmodel.pkl\", \"wb\") as file: pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For saving models:'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"For saving models:\"\"\"\n",
    "#with open(\"identity5.pkl\", \"wb\") as file: pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.25025781e-02 7.49995673e-01 1.87501749e-01]\n",
      " [0.00000000e+00 1.00000000e+00 7.52262820e-33]]\n",
      "[1.1825672926018316, 1.0598242347352753, 1.9520265746498267]\n",
      "min -1 -2 3\n",
      "state with min_error: 1\n",
      "state with max error: 2\n",
      "state with new min_error: 1\n",
      "state with new max error: 2\n",
      "Transition matrix after\n",
      "[[7.52262820e-33 1.00000000e+00 0.00000000e+00]\n",
      " [1.87501749e-01 7.49995673e-01 6.25025781e-02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculates and prints the state with the min/max error value(observation/performance errors) according\n",
    "to the raw errors and another error metric, which adds 1 to each state if its the min/max error value in \n",
    "that error section(eg pitch).\n",
    "This is then used to normalise the model. That means, that the transition matrix is saved in a way, that\n",
    "column/row 0 is always the unmastered-disengaged state (high error), column/row 1 is the unmastered-engaged\n",
    "state and column/row 2 is always the mastered state (low error).\n",
    "\"\"\"\n",
    "directory = \"left hand\"\n",
    "with open(\"BestThreeStates/\" + directory + \"/\" + directory + \"4.pkl\", \"rb\") as file:\n",
    "            model = pickle.load(file)\n",
    "print(\"Transition matrix\")\n",
    "print(model.transmat_)\n",
    "\n",
    "#print(\"Model means\")\n",
    "#print(model.means_)\n",
    "mus = model.means_\n",
    "\n",
    "state0 = mus[0][5] + mus[0][11]\n",
    "state1 = mus[1][5] + mus[1][11]\n",
    "state2 = mus[2][5] + mus[2][11]\n",
    "\n",
    "print([state0, state1, state2])\n",
    "\n",
    "max_error = np.argmax([state0, state1, state2])\n",
    "min_error = np.argmin([state0, state1, state2])\n",
    "\n",
    "new_max, new_min = new_error_comp(mus)\n",
    "\n",
    "print(\"state with min_error:\", min_error)\n",
    "print(\"state with max error:\", max_error)\n",
    "\n",
    "print(\"state with new min_error:\", new_min)\n",
    "print(\"state with new max error:\", new_max)\n",
    "#means\n",
    "#covariance\n",
    "#transition\n",
    "indizes = []\n",
    "\n",
    "\"\"\"\n",
    "if new_min != 2:\n",
    "    if new_min == 0:\n",
    "        indizes = [2,1,0]\n",
    "        model.transmat_ = swap_row(swap_column(model.transmat_, indizes), indizes)\n",
    "        model.means_ = swap_row(model.means_, indizes)\n",
    "    elif new_min == 1:\n",
    "        print(\"Wow, hier l√§uft was schief! Das Model sollte raus\")\n",
    "\"\"\"\n",
    "indizes = [2,1,0]\n",
    "model.transmat_ = swap_row(swap_column(model.transmat_, indizes), indizes)\n",
    "model.means_ = swap_row(model.means_, indizes)\n",
    "\n",
    "print(\"Transition matrix after\")\n",
    "print(model.transmat_)\n",
    "\n",
    "        \n",
    "#with open(\"left hand4_new.pkl\", \"wb\") as file: pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculates another min/max state in regards to errors, as described above.\n",
    "\"\"\"\n",
    "def new_error_comp(mus):\n",
    "    state0 = state1 = state2 = 0\n",
    "    for i in range(len(mus[0])):\n",
    "        emax = np.argmax([mus[0][i], mus[1][i], mus[2][i]])\n",
    "        emin = np.argmin([mus[0][i], mus[1][i], mus[2][i]])\n",
    "        if emax == 0:\n",
    "            state0 += 1\n",
    "        elif emax == 1:\n",
    "            state1 += 1\n",
    "        elif emax == 2:\n",
    "            state2 += 1\n",
    "        if emin == 0:\n",
    "            state0 -= 1\n",
    "        elif emin == 1:\n",
    "            state1 -= 1\n",
    "        elif emin == 2:\n",
    "            state2 -= 1\n",
    "    new_max = np.argmax([state0, state1, state2])\n",
    "    new_min = np.argmin([state0, state1, state2])\n",
    "    print(\"min\", state0, state1, state2)\n",
    "    return new_max, new_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_column(arr, indizes):\n",
    "    arr[:, [0,1,2]] = arr[:, indizes]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_row(arr, indizes):\n",
    "    arr[[0,1,2]] = arr[indizes]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if new_min == 0 and new_max == 2:\n",
    "    # 0 -> 2, 2-> 0\n",
    "    indizes = [2,1,0]\n",
    "elif new_min == 0 and new_max == 1:\n",
    "    # 0 -> 2, 1-> 0, 2 -> 1\n",
    "    indizes = [2,0,1]\n",
    "elif new_min == 1 and new_max == 2:\n",
    "    # 0 -> 1, 1 -> 2, 2 -> 0\n",
    "    indizes = [1,2,0]\n",
    "elif new_min == 1 and new_max == 0:\n",
    "    # 1 -> 2, 2 -> 1\n",
    "    indizes = [0,2,1]\n",
    "elif new_min == 2 and new_max == 1:\n",
    "    # 1 -> 0, 0 -> 1\n",
    "    indizes = [1,0,2]\n",
    "else:\n",
    "    indizes = [0,1,2]\n",
    "model.transmat_ = swap_row(swap_column(model.transmat_, indizes), indizes)\n",
    "model.means_ = swap_row(model.means_, indizes)\n",
    "#model.covars_ = swap_row(model.covars_, indizes)\n",
    "\n",
    "print(model.transmat_)\n",
    "#wit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
