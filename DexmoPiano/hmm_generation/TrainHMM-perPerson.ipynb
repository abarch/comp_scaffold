{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This files is for training/generating HMMs of **only one person at a time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split data into sequences (see splitData.ipynb) for one person.\n",
    "\"\"\"\n",
    "def get_data(filename):\n",
    "    X = []\n",
    "    lengths = []\n",
    "    file = pd.read_csv(filename, names=[\"score1\",\"score2\",\"pm\", \"level\", \"pitch_right\", \"note_hold_time_right\",\n",
    "                                         \"timing_right\", \"n_missing_notes_right\", \"n_extra_notes_right\",\n",
    "                                         \"summed_right\", \"pitch_left\", \"note_hold_time_left\",\n",
    "                                         \"timing_left\", \"n_missing_notes_left\", \"n_extra_notes_left\",\n",
    "                                         \"summed_left\" ])\n",
    "    pm = \"Nothin\"\n",
    "    level = None\n",
    "    pointer = -1\n",
    "    for i, row in file.iterrows():\n",
    "        if pointer >= i:\n",
    "            continue\n",
    "        elif i < 3:\n",
    "            continue\n",
    "        elif pm == row[\"pm\"] and level == row[\"level\"]:\n",
    "            X, lengths, pointer = get_sequence(file, i-1, X, lengths, pm, level)\n",
    "        else:\n",
    "            pm = row[\"pm\"]\n",
    "            level = row[\"level\"]\n",
    "    return X, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Appends the error values of the file(sequence) to X and the length of the sequence to the array lengths. \n",
    "\n",
    "@param filename: name of file/sequence\n",
    "@param X: array of error values for all practice opportunities of one practice mode\n",
    "@param lengths: array of lengths of the individual sequences\n",
    "\"\"\"\n",
    "def get_sequence(file, index, X, lengths, pm, level):\n",
    "    #print(file.loc[3])\n",
    "    i = index\n",
    "    row = file.loc[i]\n",
    "    while pm == row[\"pm\"] and level == row[\"level\"]:\n",
    "        X.append(list(row[4:]))\n",
    "        i += 1\n",
    "        if i != len(file):\n",
    "            row = file.loc[i]\n",
    "        else:\n",
    "            break\n",
    "    lengths.append(i - index)\n",
    "    return X, lengths, i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tries to find the best HMM, by returning the model with the highest score/log probability. Note that this is\n",
    "not necessarily the most reasonable, most-fitting model to the data, so exploring other models is important!\n",
    "\n",
    "@param filename: practice mode\n",
    "\n",
    "@return modelBest: model with the highest logProb\n",
    "@return logProbMax: the highest logProb\n",
    "@return PBest: the transition matrix corresponding to the best model\n",
    "\"\"\"\n",
    "def findBestHMM(filename):\n",
    "    logProbMax = 0\n",
    "    modelBest = None\n",
    "    PBest = None\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            model, mus, sigmas, P, logProb, convergence = fitHMM(X, lengths)\n",
    "            if logProb > logProbMax and convergence.converged == True: #wrong do not use -> all not just highest score\n",
    "                logProbMax = logProb\n",
    "                modelBest = model\n",
    "                PBest = P \n",
    "        except:\n",
    "            continue\n",
    "    with open(filename + \".pkl\", \"wb\") as file: pickle.dump(modelBest, file)\n",
    "    return modelBest, logProbMax, PBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates a Hidden Markov Model. The startprobability and initial transition probability should \n",
    "be varied between retries.\n",
    "\n",
    "@return model:\n",
    "@return mus: means of states\n",
    "@return sigmas: covariance matrix\n",
    "@return P: transition probability\n",
    "@return logProb:score of model\n",
    "@return convergence: monitors convergence of model\n",
    "\"\"\"\n",
    "def fitHMM(X, lengths):\n",
    "    # fit Gaussian HMM to Q\n",
    "    model = hmm.GaussianHMM(n_components=3, n_iter=1000, init_params=\"cm\")\n",
    "    \n",
    "    model.startprob_ = np.array([0.0, 1.0, 0.0]) # same initial state\n",
    "    model.transmat_ = np.array([[0.8, 0.2, 0.0], # initial prob matrix, important is 0 in (1,3) (3,1) (3,2)\n",
    "                                [0.05, 0.8, 0.15],\n",
    "                                [0.0, 0.0, 1.0]])\n",
    "     \n",
    "    model.fit(X, lengths)\n",
    "    # classify each observation as state 0 or 1\n",
    "    #hidden_states = model.predict(X)\n",
    " \n",
    "    # find parameters of Gaussian HMM\n",
    "    convergence = model.monitor_\n",
    "    mus = np.array(model.means_)\n",
    "    sigmas = np.array(np.sqrt(np.array([np.diag(model.covars_[0]),np.diag(model.covars_[1])])))\n",
    "    P = np.array(model.transmat_)\n",
    " \n",
    "    # find log-likelihood of Gaussian HMM\n",
    "    logProb = model.score(X, lengths)\n",
    " \n",
    "    return model, mus, sigmas, P, logProb, convergence #hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n data1\n",
      "P [[1.00000000e+00 2.38786289e-25 0.00000000e+00]\n",
      " [7.40740739e-02 7.03703705e-01 2.22222221e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 730.4771739996539\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[158.74006139861902, 683.9830798302784, 730.4771727039857, 730.4771739996538],\n",
      "    iter=4,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 2 2 2 2]\n",
      "[1 2 2 2 2 2 2 2]\n",
      "[1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1]\n",
      "[1 1 1]\n",
      "[1 2]\n",
      "[1 2 2]\n",
      "[1 2 2 2]\n",
      "[1 1 1 1]\n",
      "[1 1 1]\n",
      "[1 2 2 2 2 2]\n",
      "[1 1 1]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "/n data2\n",
      "P [[1.00000000e+00 4.03911967e-36 0.00000000e+00]\n",
      " [7.31707317e-02 9.26829268e-01 7.06506493e-72]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 1185.7857464040442\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[516.9910062096599, 1179.7974104162427, 1185.7857463969572, 1185.785746404044],\n",
      "    iter=4,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "[1 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "/n data3\n",
      "P [[1.00000000e+00 7.09515715e-21 0.00000000e+00]\n",
      " [5.00000000e-01 1.20662287e-32 5.00000000e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 1845.5433724934728\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[1472.7435198215776, 1825.4569865441572, 1845.1189546686728, 1845.543371926644, 1845.543372493473],\n",
      "    iter=5,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "/n data5\n",
      "P [[1.00000000e+00 2.83194555e-34 0.00000000e+00]\n",
      " [1.38609459e-01 6.39662523e-01 2.21728018e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 762.3625003813979\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[356.51409396912413, 735.1661862888476, 762.2676123227781, 762.3627665344748, 762.362703957186],\n",
      "    iter=5,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1]\n",
      "[1 0 0]\n",
      "[1 0 0 0 0 0 0 0]\n",
      "[1 0 0]\n",
      "[1 2 2]\n",
      "[1 2 2]\n",
      "[1 0 0]\n",
      "[1 2 2 2 2 2]\n",
      "[1 2 2]\n",
      "[1 2 2]\n",
      "[1 2 2 2 2]\n",
      "[1 0 0 0]\n",
      "[1 2 2]\n",
      "[1 2 2 2]\n",
      "[1 1 1 1 1 1 1]\n",
      "/n data6\n",
      "P [[1.00000000e+00 1.88020227e-45 0.00000000e+00]\n",
      " [6.12244897e-02 9.18367347e-01 2.04081632e-02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 1435.1049607219832\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[647.9798700137133, 1372.4202716807922, 1435.1049459349842, 1435.104960721982],\n",
      "    iter=4,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "[1 2 2 2 2 2 2 2 2 2 2 2]\n",
      "/n data7\n",
      "P [[1.00000000e+00 1.47821010e-32 0.00000000e+00]\n",
      " [5.70826696e-02 9.14285715e-01 2.86316151e-02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 1450.0960696349143\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[822.8088985191386, 1438.1931050265512, 1450.056731905948, 1450.0949274042216, 1450.096039077245],\n",
      "    iter=5,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[1 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1]\n",
      "/n data8\n",
      "P [[2.37152578e-104 1.00000000e+000 0.00000000e+000]\n",
      " [7.61799896e-109 8.75000420e-001 1.24999580e-001]\n",
      " [0.00000000e+000 0.00000000e+000 1.00000000e+000]]\n",
      "logProb 1870.0163931187633\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[1329.9140583786154, 1829.5108381950809, 1866.8476706407023, 1869.6207058450443, 1870.01586946214, 1870.0163928503077],\n",
      "    iter=6,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "/n data9\n",
      "P [[1.00000000e+00 4.59011021e-25 0.00000000e+00]\n",
      " [1.99999995e-01 7.00000007e-01 9.99999975e-02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 1441.748286253688\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[787.8537986330905, 1441.6101587340686, 1441.7482862520321, 1441.748286253688],\n",
      "    iter=4,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1]\n",
      "[1 1 1 1]\n",
      "[1 1 1]\n",
      "/n data10\n",
      "P [[1.00000000e+00 9.75575339e-30 0.00000000e+00]\n",
      " [8.69565217e-02 8.69565217e-01 4.34782609e-02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 1350.2049886489795\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[579.1643321954746, 1334.7757023741428, 1350.2049886489303, 1350.2049886489792],\n",
      "    iter=4,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1]\n",
      "/n data11\n",
      "P [[9.99999997e-01 3.05171283e-09 0.00000000e+00]\n",
      " [7.84429907e-02 8.16948973e-01 1.04608036e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 951.7368858823852\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[476.9978898205811, 918.1326206746859, 951.7272800327005, 951.7411851861373, 951.737638026968],\n",
      "    iter=5,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[1 2 2 2 2]\n",
      "[1 2 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1]\n",
      "[1 2 2 2]\n",
      "[1 1 1 1 1]\n",
      "[1 0 0 0]\n",
      "[1 0 0 0 0 0]\n",
      "[1 0 0 0 0 0]\n",
      "/n data12\n",
      "P [[1.00000000e+00 1.07404532e-26 0.00000000e+00]\n",
      " [3.22580645e-02 9.67741935e-01 2.50051105e-96]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "logProb 857.3033370345845\n",
      "convergences ConvergenceMonitor(\n",
      "    history=[661.7011758268745, 857.3023687737283, 857.3033370345288],\n",
      "    iter=3,\n",
      "    n_iter=1000,\n",
      "    tol=0.01,\n",
      "    verbose=False,\n",
      ")\n",
      "\n",
      "[1 1 1]\n",
      "[1 0 0]\n",
      "[1 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main: Generates models for one practice mode (directory) or iteratively for all (don't forget to save them\n",
    "in that case).\n",
    "\"\"\"\n",
    "lengths = []\n",
    "X = [] #, \"data4\"\n",
    "for filename in [\"data1\", \"data2\", \"data3\", \"data5\", \"data6\", \"data7\", \"data8\", \"data9\", \"data10\", \"data11\", \"data12\"]:\n",
    "    X, lengths = get_data(\"Data_Anonym\" + \"/\" + filename + \".csv\")\n",
    "    model, mus, sigmas, P, logProb, convergence = fitHMM(X, lengths) #directory equals practice mode\n",
    "    #model, logProb, P = findBestHMM(directory)\n",
    "    print(\"/n\", filename)\n",
    "    print(\"P\", P)\n",
    "    print(\"logProb\", logProb)\n",
    "    #print(\"means\", mus)\n",
    "    print(\"convergences\", convergence)\n",
    "    print(\"\")\n",
    "    hidden_state = model.predict(X, lengths)\n",
    "    index = 0\n",
    "    for length in lengths:\n",
    "        print(hidden_state[index:index+length])\n",
    "        index += length\n",
    "    #with open(filename + \"_1.pkl\", \"wb\") as file: pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For saving models:'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"For saving models:\"\"\"\n",
    "#with open(\"identity5.pkl\", \"wb\") as file: pickle.dump(model, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.25025781e-02 7.49995673e-01 1.87501749e-01]\n",
      " [0.00000000e+00 1.00000000e+00 7.52262820e-33]]\n",
      "[1.1825672926018316, 1.0598242347352753, 1.9520265746498267]\n",
      "min -1 -2 3\n",
      "state with min_error: 1\n",
      "state with max error: 2\n",
      "state with new min_error: 1\n",
      "state with new max error: 2\n",
      "Wow, hier läuft was schief! Das Model sollte raus\n",
      "Transition matrix after\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.25025781e-02 7.49995673e-01 1.87501749e-01]\n",
      " [0.00000000e+00 1.00000000e+00 7.52262820e-33]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculates and prints the state with the min/max error value(observation/performance errors) according\n",
    "to the raw errors and another error metric, which adds 1 to each state if its the min/max error value in \n",
    "that error section(eg pitch).\n",
    "This is then used to normalise the model. That means, that the transition matrix is saved in a way, that\n",
    "column/row 0 is always the unmastered-disengaged state (high error), column/row 1 is the unmastered-engaged\n",
    "state and column/row 2 is always the mastered state (low error).\n",
    "\"\"\"\n",
    "directory = \"left hand\"\n",
    "with open(\"BestThreeStates/\" + directory + \"/\" + directory + \"4.pkl\", \"rb\") as file:\n",
    "            model = pickle.load(file)\n",
    "print(\"Transition matrix\")\n",
    "print(model.transmat_)\n",
    "\n",
    "#print(\"Model means\")\n",
    "#print(model.means_)\n",
    "mus = model.means_\n",
    "\n",
    "state0 = mus[0][5] + mus[0][11]\n",
    "state1 = mus[1][5] + mus[1][11]\n",
    "state2 = mus[2][5] + mus[2][11]\n",
    "\n",
    "print([state0, state1, state2])\n",
    "\n",
    "max_error = np.argmax([state0, state1, state2])\n",
    "min_error = np.argmin([state0, state1, state2])\n",
    "\n",
    "new_max, new_min = new_error_comp(mus)\n",
    "\n",
    "print(\"state with min_error:\", min_error)\n",
    "print(\"state with max error:\", max_error)\n",
    "\n",
    "print(\"state with new min_error:\", new_min)\n",
    "print(\"state with new max error:\", new_max)\n",
    "#means\n",
    "#covariance\n",
    "#transition\n",
    "indizes = []\n",
    "\n",
    "\n",
    "if new_min != 2:\n",
    "    if new_min == 0:\n",
    "        indizes = [2,1,0]\n",
    "        model.transmat_ = swap_row(swap_column(model.transmat_, indizes), indizes)\n",
    "        model.means_ = swap_row(model.means_, indizes)\n",
    "    elif new_min == 1:\n",
    "        print(\"Wow, hier läuft was schief! Das Model sollte raus\")\n",
    "\"\"\"\n",
    "indizes = [2,1,0]\n",
    "model.transmat_ = swap_row(swap_column(model.transmat_, indizes), indizes)\n",
    "model.means_ = swap_row(model.means_, indizes)\n",
    "\"\"\"\n",
    "print(\"Transition matrix after\")\n",
    "print(model.transmat_)\n",
    "\n",
    "        \n",
    "with open(\"left hand4_new.pkl\", \"wb\") as file: pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculates another min/max state in regards to errors, as described above.\n",
    "\"\"\"\n",
    "def new_error_comp(mus):\n",
    "    state0 = state1 = state2 = 0\n",
    "    for i in range(len(mus[0])):\n",
    "        emax = np.argmax([mus[0][i], mus[1][i], mus[2][i]])\n",
    "        emin = np.argmin([mus[0][i], mus[1][i], mus[2][i]])\n",
    "        if emax == 0:\n",
    "            state0 += 1\n",
    "        elif emax == 1:\n",
    "            state1 += 1\n",
    "        elif emax == 2:\n",
    "            state2 += 1\n",
    "        if emin == 0:\n",
    "            state0 -= 1\n",
    "        elif emin == 1:\n",
    "            state1 -= 1\n",
    "        elif emin == 2:\n",
    "            state2 -= 1\n",
    "    new_max = np.argmax([state0, state1, state2])\n",
    "    new_min = np.argmin([state0, state1, state2])\n",
    "    print(\"min\", state0, state1, state2)\n",
    "    return new_max, new_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_column(arr, indizes):\n",
    "    arr[:, [0,1,2]] = arr[:, indizes]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_row(arr, indizes):\n",
    "    arr[[0,1,2]] = arr[indizes]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif new_min == 0 and new_max == 2:\\n    # 0 -> 2, 2-> 0\\n    indizes = [2,1,0]\\nelif new_min == 0 and new_max == 1:\\n    # 0 -> 2, 1-> 0, 2 -> 1\\n    indizes = [2,0,1]\\nelif new_min == 1 and new_max == 2:\\n    # 0 -> 1, 1 -> 2, 2 -> 0\\n    indizes = [1,2,0]\\nelif new_min == 1 and new_max == 0:\\n    # 1 -> 2, 2 -> 1\\n    indizes = [0,2,1]\\nelif new_min == 2 and new_max == 1:\\n    # 1 -> 0, 0 -> 1\\n    indizes = [1,0,2]\\nelse:\\n    indizes = [0,1,2]\\nmodel.transmat_ = swap_row(swap_column(model.transmat_, indizes), indizes)\\nmodel.means_ = swap_row(model.means_, indizes)\\n#model.covars_ = swap_row(model.covars_, indizes)\\n\\nprint(model.transmat_)\\n#wit\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "if new_min == 0 and new_max == 2:\n",
    "    # 0 -> 2, 2-> 0\n",
    "    indizes = [2,1,0]\n",
    "elif new_min == 0 and new_max == 1:\n",
    "    # 0 -> 2, 1-> 0, 2 -> 1\n",
    "    indizes = [2,0,1]\n",
    "elif new_min == 1 and new_max == 2:\n",
    "    # 0 -> 1, 1 -> 2, 2 -> 0\n",
    "    indizes = [1,2,0]\n",
    "elif new_min == 1 and new_max == 0:\n",
    "    # 1 -> 2, 2 -> 1\n",
    "    indizes = [0,2,1]\n",
    "elif new_min == 2 and new_max == 1:\n",
    "    # 1 -> 0, 0 -> 1\n",
    "    indizes = [1,0,2]\n",
    "else:\n",
    "    indizes = [0,1,2]\n",
    "model.transmat_ = swap_row(swap_column(model.transmat_, indizes), indizes)\n",
    "model.means_ = swap_row(model.means_, indizes)\n",
    "#model.covars_ = swap_row(model.covars_, indizes)\n",
    "\n",
    "print(model.transmat_)\n",
    "#wit\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
